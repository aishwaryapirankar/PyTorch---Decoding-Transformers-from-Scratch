{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Coding Decoder-Only Transformers from Scratch","metadata":{}},{"cell_type":"code","source":"#Import required modules\nimport pip\ntry:\n  __import__(\"lightning\")\nexcept ImportError:\n  pip.main(['install', \"lightning\"])  # if lightning is not installed\n\nimport torch\nimport torch.nn as nn \nimport torch.nn.functional as F\n\nfrom torch.optim import Adam\nfrom torch.utils.data import TensorDataset, DataLoader\n\nimport lightning as L","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T10:16:17.224690Z","iopub.execute_input":"2025-03-04T10:16:17.225033Z","iopub.status.idle":"2025-03-04T10:16:35.140902Z","shell.execute_reply.started":"2025-03-04T10:16:17.224996Z","shell.execute_reply":"2025-03-04T10:16:35.139746Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n  warnings.warn(\nWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\nPlease see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\nTo avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Collecting lightning\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Collecting lightning\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e77494ab40d48c4ae9aeeffb2681414"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.2)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: PyYAML&lt;8.0,&gt;=5.4 in /usr/local/lib/python3.10/dist-packages (from lightning) (6.0.2)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.12.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: fsspec&lt;2026.0,&gt;=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (2024.12.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.12.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: lightning-utilities&lt;2.0,&gt;=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (0.12.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: packaging<25.0,>=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (24.2)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: packaging&lt;25.0,&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (24.2)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: torch<4.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.5.1+cu121)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: torch&lt;4.0,&gt;=2.1.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.5.1+cu121)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.6.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: torchmetrics&lt;3.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (1.6.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.67.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: tqdm&lt;6.0,&gt;=4.57.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.67.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.12.2)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: typing-extensions&lt;6.0,&gt;=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.12.2)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning) (2.5.0.post0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning) (2.5.0.post0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.11.12)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (3.11.12)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (75.1.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities&lt;2.0,&gt;=0.10.0-&gt;lightning) (75.1.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.17.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch&lt;4.0,&gt;=2.1.0-&gt;lightning) (3.17.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.4.2)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch&lt;4.0,&gt;=2.1.0-&gt;lightning) (3.4.2)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (3.1.4)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch&lt;4.0,&gt;=2.1.0-&gt;lightning) (3.1.4)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=2.1.0->lightning) (1.13.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch&lt;4.0,&gt;=2.1.0-&gt;lightning) (1.13.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<4.0,>=2.1.0->lightning) (1.3.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1-&gt;torch&lt;4.0,&gt;=2.1.0-&gt;lightning) (1.3.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.4)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: numpy&gt;1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics&lt;3.0,&gt;=0.7.0-&gt;lightning) (1.26.4)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (2.4.6)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: aiohappyeyeballs&gt;=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (2.4.6)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.2)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (1.3.2)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (5.0.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: async-timeout&lt;6.0,&gt;=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (5.0.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (25.1.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (25.1.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.5.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (1.5.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.1.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (6.1.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (0.2.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: propcache&gt;=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (0.2.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.18.3)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: yarl&lt;2.0,&gt;=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (1.18.3)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.3.8)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy&gt;1.20.0-&gt;torchmetrics&lt;3.0,&gt;=0.7.0-&gt;lightning) (1.3.8)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.2.4)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy&gt;1.20.0-&gt;torchmetrics&lt;3.0,&gt;=0.7.0-&gt;lightning) (1.2.4)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (0.1.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy&gt;1.20.0-&gt;torchmetrics&lt;3.0,&gt;=0.7.0-&gt;lightning) (0.1.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2025.0.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy&gt;1.20.0-&gt;torchmetrics&lt;3.0,&gt;=0.7.0-&gt;lightning) (2025.0.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2022.0.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy&gt;1.20.0-&gt;torchmetrics&lt;3.0,&gt;=0.7.0-&gt;lightning) (2022.0.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2.4.1)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy&gt;1.20.0-&gt;torchmetrics&lt;3.0,&gt;=0.7.0-&gt;lightning) (2.4.1)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (3.0.2)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch&lt;4.0,&gt;=2.1.0-&gt;lightning) (3.0.2)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.10)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: idna&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl&lt;2.0,&gt;=1.17.0-&gt;aiohttp!=4.0.0a0,!=4.0.0a1-&gt;fsspec[http]&lt;2026.0,&gt;=2022.5.0-&gt;lightning) (3.10)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: intel-openmp&gt;=2024 in /usr/local/lib/python3.10/dist-packages (from mkl-&gt;numpy&gt;1.20.0-&gt;torchmetrics&lt;3.0,&gt;=0.7.0-&gt;lightning) (2024.2.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2022.0.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl-&gt;numpy&gt;1.20.0-&gt;torchmetrics&lt;3.0,&gt;=0.7.0-&gt;lightning) (2022.0.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (1.2.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*-&gt;mkl-&gt;numpy&gt;1.20.0-&gt;torchmetrics&lt;3.0,&gt;=0.7.0-&gt;lightning) (1.2.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath-&gt;numpy&gt;1.20.0-&gt;torchmetrics&lt;3.0,&gt;=0.7.0-&gt;lightning) (2024.2.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>1.20.0->torchmetrics<3.0,>=0.7.0->lightning) (2024.2.0)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp&gt;=2024-&gt;mkl-&gt;numpy&gt;1.20.0-&gt;torchmetrics&lt;3.0,&gt;=0.7.0-&gt;lightning) (2024.2.0)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Downloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c742e6550cf146a0bac1491877ef9653"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Installing collected packages: lightning\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Installing collected packages: lightning\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Successfully installed lightning-2.5.0.post0\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Successfully installed lightning-2.5.0.post0\n</pre>\n"},"metadata":{}}],"execution_count":1},{"cell_type":"markdown","source":"Create input and output data:\nInput: What is PyTorch?\nOutput: Interesting","metadata":{}},{"cell_type":"code","source":"# Create dictionary that maps vocabulary to numbers\ntoken_to_id = {'what': 0,\n              'is': 1,\n              'PyTorch': 2,\n              'Interesting': 3,\n              '<EOS>': 4, #EOS is the end of sequence\n              }\n\n# Dictionary that maps ID to tokens to interpret output\nid_to_token = dict(map(reversed, token_to_id.items()))\nprint(id_to_token)\n\n#Inputs will contain the questions - \"What is PyTorch?\"\", \"PyTorch is what?\" followed by response \"Interesting\"\ninputs = torch.tensor([[token_to_id[\"what\"], ## input #1: What is PyTorch <EOS> Intersting\n                        token_to_id[\"is\"], \n                        token_to_id[\"PyTorch\"], \n                        token_to_id[\"<EOS>\"],\n                        token_to_id[\"Interesting\"]], \n                       \n                       [token_to_id[\"PyTorch\"], # input #2: PyTorch is what <EOS> Intersting\n                        token_to_id[\"is\"], \n                        token_to_id[\"what\"], \n                        token_to_id[\"<EOS>\"], \n                        token_to_id[\"Interesting\"]]])\n\nlabels = torch.tensor([[token_to_id[\"is\"], \n                        token_to_id[\"PyTorch\"], \n                        token_to_id[\"<EOS>\"], \n                        token_to_id[\"Interesting\"], \n                        token_to_id[\"<EOS>\"]],  \n                       \n                       [token_to_id[\"is\"], \n                        token_to_id[\"what\"], \n                        token_to_id[\"<EOS>\"], \n                        token_to_id[\"Interesting\"], \n                        token_to_id[\"<EOS>\"]]])\n\n# Merge into a DataLoader\ndataset = TensorDataset(inputs,labels)\ndataloader = DataLoader(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T10:16:35.142055Z","iopub.execute_input":"2025-03-04T10:16:35.142582Z","iopub.status.idle":"2025-03-04T10:16:35.153267Z","shell.execute_reply.started":"2025-03-04T10:16:35.142550Z","shell.execute_reply":"2025-03-04T10:16:35.152309Z"}},"outputs":[{"name":"stdout","text":"{0: 'what', 1: 'is', 2: 'PyTorch', 3: 'Interesting', 4: '<EOS>'}\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":" Embedding and Positional Encoding\n> NOTE: The reason why we are bothering to create a class to do positional encoding, instead of just adding this code directly to the transformer, is that we can easily re-use it in an Encoder-Only Transformer or an Encoder-Decoder Transformer. So, by creating a class that does positional encoding, we can code it once, and then just create instances when and where we need it.\n\n> ALSO NOTE: Since the position encoding values never change, meaning that the first token always uses the same position encoding values regardless of what that token is, we precompute them and save them in a lookup table. This makes adding position encoding values super fast.\n\n  ","metadata":{}},{"cell_type":"code","source":"class PositionEncoding(nn.Module):\n    def __init__(self, d_model=2, max_len=6):  #dmodel is the dimension of the transformer (No. of embeddings per token), max_len is the no. of tokens we allow as input\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n        embedding_index = torch.arange(start=0, end=d_model, step=2).float()\n        \n        div_term = 1/torch.tensor(10000.0)**(embedding_index / d_model)\n\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n\n        self.register_buffer('pe', pe)\n\n    def forward(self, word_embeddings):\n        return word_embeddings + self.pe[:word_embeddings.size(0), :]\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T10:16:35.155588Z","iopub.execute_input":"2025-03-04T10:16:35.156084Z","iopub.status.idle":"2025-03-04T10:16:35.183776Z","shell.execute_reply.started":"2025-03-04T10:16:35.156042Z","shell.execute_reply":"2025-03-04T10:16:35.182572Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Attention class","metadata":{}},{"cell_type":"code","source":"class Attention(nn.Module): \n    \n    def __init__(self, d_model=2):\n        super().__init__()\n        self.d_model=d_model\n        \n        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n\n        self.row_dim = 0\n        self.col_dim = 1\n\n        \n    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask=None):\n        q = self.W_q(encodings_for_q)\n        k = self.W_k(encodings_for_k)\n        v = self.W_v(encodings_for_v)\n\n        sims = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n\n        scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n\n        if mask is not None:\n            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n        \n        # Apply softmax to determine what percent of each token's value to use in the final attention values.\n        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n\n        # Scale the values by their associated percentages and add them up.\n        attention_scores = torch.matmul(attention_percents, v)\n        \n        return attention_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T10:17:51.447529Z","iopub.execute_input":"2025-03-04T10:17:51.447956Z","iopub.status.idle":"2025-03-04T10:17:51.456809Z","shell.execute_reply.started":"2025-03-04T10:17:51.447922Z","shell.execute_reply":"2025-03-04T10:17:51.455350Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"Decoder-Only Transformer\n\n**A Decoder-Only Transformer simply brings together...**\n\n\n* Word Embedding\n* Position Encoding\n* Masked Self-Attention\n* Residual Connections\n* A fully connected layer\n* SoftMax - However, the loss function we are using nn.CrossEntropyLoss(), applies the SoftMax for us.\n","metadata":{}},{"cell_type":"code","source":"class DecoderOnlyTransformer(L.LightningModule):\n    \n    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n        super().__init__()\n        L.seed_everything(seed=42)\n        \n        self.we = nn.Embedding(num_embeddings=num_tokens, embedding_dim=d_model)     \n        \n        self.pe = PositionEncoding(d_model=d_model, max_len=max_len)\n\n        self.self_attention = Attention(d_model=d_model)\n\n        self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n        \n        self.loss = nn.CrossEntropyLoss()\n        \n        \n    def forward(self, token_ids):\n                \n        word_embeddings = self.we(token_ids)        \n        position_encoded = self.pe(word_embeddings)\n\n        mask = torch.tril(torch.ones((token_ids.size(dim=0), token_ids.size(dim=0)), device=self.device))\n        mask = mask == 0\n        \n        self_attention_values = self.self_attention(position_encoded, \n                                                    position_encoded, \n                                                    position_encoded, \n                                                    mask=mask)\n        \n        residual_connection_values = position_encoded + self_attention_values\n        \n        fc_layer_output = self.fc_layer(residual_connection_values)\n        \n        return fc_layer_output\n    \n    \n    def configure_optimizers(self): \n        return Adam(self.parameters(), lr=0.1)\n    \n    \n    def training_step(self, batch, batch_idx): \n        input_tokens, labels = batch # collect input\n        output = self.forward(input_tokens[0])\n        loss = self.loss(output, labels[0])\n                    \n        return loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T10:25:48.863566Z","iopub.execute_input":"2025-03-04T10:25:48.864072Z","iopub.status.idle":"2025-03-04T10:25:48.876112Z","shell.execute_reply.started":"2025-03-04T10:25:48.864024Z","shell.execute_reply":"2025-03-04T10:25:48.874745Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Decoder-Only Transformer - Without Training","metadata":{}},{"cell_type":"code","source":"## First, create a model from DecoderOnlyTransformer()\nmodel = DecoderOnlyTransformer(num_tokens=len(token_to_id), d_model=2, max_len=6)\n\nmodel_input = torch.tensor([token_to_id[\"what\"], \n                            token_to_id[\"is\"], \n                            token_to_id[\"PyTorch\"], \n                            token_to_id[\"<EOS>\"]])\ninput_length = model_input.size(dim=0)\n\n## predictions from the model\npredictions = model(model_input) \npredicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\npredicted_ids = predicted_id\n\n## use a loop to predict output tokens until we get an <EOS> token.\nmax_length = 6\nfor i in range(input_length, max_length):\n    if (predicted_id == token_to_id[\"<EOS>\"]): # if the prediction is <EOS>, then we are done\n        break\n    \n    model_input = torch.cat((model_input, predicted_id))\n    \n    predictions = model(model_input) \n    predicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\n    predicted_ids = torch.cat((predicted_ids, predicted_id))\n        \n## Now printout the predicted output phrase.\nprint(\"Predicted Tokens:\\n\") \nfor id in predicted_ids: \n    print(\"\\t\", id_to_token[id.item()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T11:02:09.174865Z","iopub.execute_input":"2025-03-04T11:02:09.175294Z","iopub.status.idle":"2025-03-04T11:02:09.372468Z","shell.execute_reply.started":"2025-03-04T11:02:09.175262Z","shell.execute_reply":"2025-03-04T11:02:09.371233Z"}},"outputs":[{"name":"stderr","text":"INFO: Seed set to 42\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Seed set to 42\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Seed set to 42\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Predicted Tokens:\n\n\t <EOS>\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Training the Decoder-Only Transformer","metadata":{}},{"cell_type":"code","source":"trainer = L.Trainer(max_epochs=30)\ntrainer.fit(model, train_dataloaders=dataloader)\n\nmodel_input = torch.tensor([token_to_id[\"what\"], \n                            token_to_id[\"is\"], \n                            token_to_id[\"PyTorch\"], \n                            token_to_id[\"<EOS>\"]])\ninput_length = model_input.size(dim=0)\n\npredictions = model(model_input) \npredicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\npredicted_ids = predicted_id\n\nfor i in range(input_length, max_length):\n    if (predicted_id == token_to_id[\"<EOS>\"]): # if the prediction is <EOS>, then we are done\n        break\n    \n    model_input = torch.cat((model_input, predicted_id))\n    \n    predictions = model(model_input) \n    predicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\n    predicted_ids = torch.cat((predicted_ids, predicted_id))\n        \nprint(\"Predicted Tokens:\\n\") \nfor id in predicted_ids: \n    print(\"\\t\", id_to_token[id.item()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T11:04:06.181672Z","iopub.execute_input":"2025-03-04T11:04:06.182071Z","iopub.status.idle":"2025-03-04T11:04:23.615302Z","shell.execute_reply.started":"2025-03-04T11:04:06.182042Z","shell.execute_reply":"2025-03-04T11:04:23.614354Z"}},"outputs":[{"name":"stderr","text":"INFO: GPU available: False, used: False\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"GPU available: False, used: False\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">GPU available: False, used: False\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"INFO: TPU available: False, using: 0 TPU cores\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"TPU available: False, using: 0 TPU cores\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TPU available: False, using: 0 TPU cores\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"INFO: HPU available: False, using: 0 HPUs\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"HPU available: False, using: 0 HPUs\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">HPU available: False, using: 0 HPUs\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"NumExpr defaulting to 4 threads.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">NumExpr defaulting to 4 threads.\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"INFO: \n  | Name           | Type             | Params | Mode \n------------------------------------------------------------\n0 | we             | Embedding        | 10     | train\n1 | pe             | PositionEncoding | 0      | train\n2 | self_attention | Attention        | 12     | train\n3 | fc_layer       | Linear           | 15     | train\n4 | loss           | CrossEntropyLoss | 0      | train\n------------------------------------------------------------\n37        Trainable params\n0         Non-trainable params\n37        Total params\n0.000     Total estimated model params size (MB)\n8         Modules in train mode\n0         Modules in eval mode\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\n  | Name           | Type             | Params | Mode \n------------------------------------------------------------\n0 | we             | Embedding        | 10     | train\n1 | pe             | PositionEncoding | 0      | train\n2 | self_attention | Attention        | 12     | train\n3 | fc_layer       | Linear           | 15     | train\n4 | loss           | CrossEntropyLoss | 0      | train\n------------------------------------------------------------\n37        Trainable params\n0         Non-trainable params\n37        Total params\n0.000     Total estimated model params size (MB)\n8         Modules in train mode\n0         Modules in eval mode\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n  | Name           | Type             | Params | Mode \n------------------------------------------------------------\n0 | we             | Embedding        | 10     | train\n1 | pe             | PositionEncoding | 0      | train\n2 | self_attention | Attention        | 12     | train\n3 | fc_layer       | Linear           | 15     | train\n4 | loss           | CrossEntropyLoss | 0      | train\n------------------------------------------------------------\n37        Trainable params\n0         Non-trainable params\n37        Total params\n0.000     Total estimated model params size (MB)\n8         Modules in train mode\n0         Modules in eval mode\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/usr/local/lib/python3.10/dist-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"306de597e172494aa1cb77fda710655b"}},"metadata":{}},{"name":"stderr","text":"INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"`Trainer.fit` stopped: `max_epochs=30` reached.\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">`Trainer.fit` stopped: `max_epochs=30` reached.\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Predicted Tokens:\n\n\t Interesting\n\t <EOS>\n","output_type":"stream"}],"execution_count":7},{"cell_type":"raw","source":"Response to 'PyTorch is what?'","metadata":{}},{"cell_type":"code","source":"## Now let's ask the other question...\nmodel_input = torch.tensor([token_to_id[\"PyTorch\"], \n                            token_to_id[\"is\"], \n                            token_to_id[\"what\"], \n                            token_to_id[\"<EOS>\"]])\ninput_length = model_input.size(dim=0)\n\npredictions = model(model_input) \npredicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\npredicted_ids = predicted_id\n\nfor i in range(input_length, max_length):\n    if (predicted_id == token_to_id[\"<EOS>\"]): # if the prediction is <EOS>, then we are done\n        break\n    \n    model_input = torch.cat((model_input, predicted_id))\n    \n    predictions = model(model_input) \n    predicted_id = torch.tensor([torch.argmax(predictions[-1,:])])\n    predicted_ids = torch.cat((predicted_ids, predicted_id))\n        \nprint(\"Predicted Tokens:\\n\") \nfor id in predicted_ids: \n    print(\"\\t\", id_to_token[id.item()])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T11:05:03.861692Z","iopub.execute_input":"2025-03-04T11:05:03.862167Z","iopub.status.idle":"2025-03-04T11:05:03.875801Z","shell.execute_reply.started":"2025-03-04T11:05:03.862128Z","shell.execute_reply":"2025-03-04T11:05:03.874374Z"}},"outputs":[{"name":"stdout","text":"Predicted Tokens:\n\n\t Interesting\n\t <EOS>\n","output_type":"stream"}],"execution_count":8}]}